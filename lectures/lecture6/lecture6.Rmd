---
title: "Lecture 6: Tidy data"
subtitle:  "EDUC 263: Managing and Manipulating Data Using R"
author: Ozan Jaquette
date: 
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: # toc_float option to float the table of contents to the left of the main document content. floating table of contents will always be visible even when the document is scrolled
      collapsed: false # collapsed (defaults to TRUE) controls whether the TOC appears with only the top-level (e.g., H2) headers. If collapsed initially, the TOC is automatically expanded inline when necessary
      smooth_scroll: true # smooth_scroll (defaults to TRUE) controls whether page scrolls are animated when TOC items are navigated to via mouse clicks
    number_sections: true
    fig_caption: true # ? this option doesn't seem to be working for figure inserted below outside of r code chunk    
    highlight: default # Supported styles include "default", "tango", "pygments", "kate", "monochrome", "espresso", "zenburn", and "haddock" (specify null to prevent syntax    
    theme: default # theme specifies the Bootstrap theme to use for the page. Valid themes include default, cerulean, journal, flatly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti.
    df_print: tibble #options: default, tibble, paged
    keep_md: true # may be helpful for storing on github
    
---

```{r, echo=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", highlight = TRUE)
```

# Introduction

Creating analysis datasets often require __changing the organizational structure__ of data

Examples:

- You want analysis dataset to have one obs per student, but your data has one obs per student-course
- You want analysis dataset to have one obs per institution, but enrollment data has one obs per institution-enrollment level

Two common ways to change organizational structure of data

1. Use `group_by` to perform calculations separately within groups and then use `summarise` to create an object with one observation per group
    - We did this in week 5
1. __Reshape__ your data -- called __tidying__ in the R tidyverse world -- by transforming columns (variables) into rows (observations) and vice-versa
    - Our topic for today

This lecture is about changing the organizational structure of your data by transforming __untidy__ data into __tidy__ data.  Working with tidy data has many benefits, one of them is that all the packages in the tidyverse are designed to work with tidy data.

Libraries we will use
```{r}
library(tidyverse)
```

We will perform data __tidying__ using functions from the __tidyr__ package, which is a package within tidyverse. 

Show index and example datasets in __tidyr__ package
```{r, eval=FALSE}
help(package="tidyr")
# note that example datasets table1, table2, etc. are listed in the index alongside functions

table1
tidyr::table1 # same same
df1 <- table1
str(df1)

table2
table3
```



Our outline for the class is as follows [CAN I AUTOMATICALLY INSERT A TOC HERE:

- INSERT TOC

# Defining tidy vs. untidy data

## Data structure and data concepts

Before we define tidy data, we should define the some concepts about datasets. This discussion draws from the 2014 article [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) by Hadley Wickham.

### Dataset structure

Dataset structure refers to the "physical layout" of a dataset

Typically, datasets are "rectangular __tables__ made up of __rows__ and __columns__" (emphasis added).

There are many alternative data structures to present the same underlying data

Below are two representations of the same underlying data that have different data structures (rows and columns transposed)
```{r}
#create structure a: treatment as columns, names as rows
structure_a <- tibble(
  name   = c("John Smith","Jane Doe","Mary Johnson"),
  treatmenta    = c(NA, 16, 3),
  treatmentb = c(2, 11, 1)
)

#create structure b: treatment as rows, names as columns
structure_b <- tibble(
  treatment   = c("treatmenta","treatmentb"),
  John_Smith    = c(NA, 2),
  Jane_Doe = c(16,11),
  Mary_Johnson = c(3,1)
)

structure_a
structure_b

```

### Dataset concepts

Wickham (2014) defines the dataset __concepts__ of , _values_, _variables_, and _observations_.  Think of these dataset _concepts_ as being distinct from dataset _structure_ (rows and columns)


```{r}
#INSERT SNIPPET OF SOME DATA DATASET HERE OR DIRECTLY BELOW
```

Wickham (2014, p. 3): "A dataset is a collection of _values_, usually either numbers (if quantitative) or strings (if qualitative). Values are organized in two ways. Every value belongs to a _variable_ and an _observation_."

- __value__: A single element within some data structure (e.g., vector, list), usually a number or a character string.
    - e.g. the value of the variable `enrollment` for a one organization in a dataset where each observation represents a postsecondary education institution
- __variables__: "A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units"
    - e.g., the variable `enrollment` is a vector that contains total enrollment for each organization in the dataset
- __observations__: "An observation contains all values measured on the same unit (like a person, or a day)...across attributes"
    - e.g., the values of each variable for one organization in a dataset where each observation represents a postsecondary education institution
- __observational unit/observational level__ [WICKHAM'S TERM; THIS IS WHAT I AM HAVING TROUBLE DEFINING]. From Wickham (2014, p 4): "In a given analysis, there may be multiple levels of observations. For example, in a trial of new allergy medication we might have three observational types: demographic data collected from each person (age, sex, race), medical data collected from each person on each day (number of sneezes, redness of eyes), and meteorological data collected on each day (temperature,
pollen count)."
    - OWN: MAYBE [BEFORE/AFTER INTRODUCING TIDY DATA YOU DISTINGUISH ACTUAL OBSERVATION LEVEL OF DATASET [WHAT EACH ROW REPRESENTS] FROM "TIDY OBSERVATION LEVEL" OF THE DATASET - WHAT EACH OBSERVATION (AND IN TURN EACH ROW) SHOULD REPRESENT IN A TIDY VERSION OF THE DATASET"


- __unit of analysis__ [my term, not Wickham's]: What each observation represents in a dataset. For example:
    - if each observation represents a student, you have student level data
    - if each observation represents a student-course, you have student-course level data
    - if each observation represents an organization-year, you have organization-year level data

These concepts seem easy on first glance, but can feel slippery on closer inspection. In particular, when you confronted with a particular dataset, sometimes it can feel confusing what the variables/observations/unit of analysis __are__ and what they __should be__.

## Rules of tidy data (defining tidy data)


Visual representation of the three rules of tidy data

![INSERT FIGURE TITLE](http://r4ds.had.co.nz/images/tidy-1.png)

?ASK PATRICIA/CRYSTAL FOR EASY WAY TO INSERT FIGURE NUMBER FOR FIGURES CREATED OUTSIDE R CODE CHUNK?

Wickham chapter 12: "There are three interrelated rules which make a dataset tidy:

1. Each variable must have its own column.
1. Each observation must have its own row.
1. Each value must have its own cell."
1. [from Wickham (2014)] 

"These three rules are interrelated because it’s impossible to only satisfy two of the three" (Wickham chapter 12)

Here is an example of tidy data:
```{r}
#help(package="tidyr")
table1
```

Question: 
- What is does each observation represent in this dataset?

## Untidy data

> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

While __all__ tidy datasets are organized the same way, untidy datasets can have several different organizational structures

Here is an example of an untidy version of the same data shown in `table1`
```{r}
#INSERT SNIPPETS OF SEVERAL DIFFERENT KINDS OF UNTIDY DATA HERE
#help(package="tidyr")
table2
```

Other examples of untidy data:
```{r, eval=FALSE}
table3

#tables 4a and 4b put the information from table1 in two separate data frames
table4a
table4b

table5
```

## Diagnosing untidy data

The first step in transforming untidy data to tidy data is diagnosing which principles of tidy data have been violated.

Recall the three principles of tidy data:

1. Each variable must have its own column.
1. Each observation must have its own row.
1. Each value must have its own cell.

Let's diagnose the problems with `table2` by answering these questions

1. Does each variable have its own column?
    - if not, how does the dataset violate this principle?
    - what _should_ the variables be?
1. Does each observation have its own row?
    - if not, how does the dataset violate this principle?
    - what does each row represent _actually_ represent?
    - what _should_ each row represent?
1. Does each value  have its own cell."
    - if not, how does the dataset violate this principle?
    
Printout of `table2`
```{r}
table2
```

Answers to these questions:

1. Does each variable have its own column? __No__
    - if not, how does the dataset violate this principle? __"number of cases" and "population" should be two different variables because they are different attributes, but in `table2` these two attribute type is recorded in the variable "type" and the associated value for each type is recroded in the variable "count"__
    - what _should_ the variables be? __country, year, cases, population__
1. Does each observation have its own row? __No__
    - if not, how does the dataset violate this principle? __there is one observation for each country-year-type, but the value sof type (population, cases) represent attributes of a unit, which should be represented by distint variables rather than rows. So `table2` has two rows per observation but it should have one row per observation__
    - what does each row represent _actually_ represent? __country-year-type__
    - what _should_ each row represent? __country-year__
1. Does each value  have its own cell." Yes.
    - if not, how does the dataset violate this principle?

## Student exercise:

For each of the following datasets -- `table1`, `table3`, `table4a`, `table4b`, and `table5` -- answer the following questions:

1. Does each variable have its own column?
    - if not, how does the dataset violate this principle?
    - what _should_ the variables be?
1. Does each observation have its own row?
    - if not, how does the dataset violate this principle?
    - what does each row represent _actually_ represent?
    - what _should_ each row represent?
1. Does each value  have its own cell."
    - if not, how does the dataset violate this principle?

We'll give you ~15 minutes for this

### `table1`
```{r}
table1
```
1. Does each variable have its own column? YES
1. Does each observation have its own row? YES
    - what does each row represent _actually_ represent? COUNTRY-YEAR
    - what _should_ each row represent? COUNTERY-YEAR
1. Does each value  have its own cell." YES

### `table3`
```{r}
table3
```

1. Does each variable have its own column? __No__
    - if not, how does the dataset violate this principle? __The column `rate` contains two variables, `cases` and `population`__
    - what _should_ the variables be? __country, year, cases, population__
1. Does each observation have its own row? __Yes__
    - what does each row represent _actually_ represent? __country-year__
    - what _should_ each row represent? __country-year__
1. Does each value  have its own cell." __No__
    - if not, how does the dataset violate this principle? __In the `rate` column, each cell contains two values, a value for `cases` and a value for `population`__
    
### `table4a`
```{r}
table4a
```
1. Does each variable have its own column? __No__
    - if not, how does the dataset violate this principle? __The variable `cases` is spread over two columns and the variable `year` is also spread over two columns__
    - what _should_ the variables be? __country, year, cases__
1. Does each observation have its own row? __No__
    - if not, how does the dataset violate this principle? __There are two country-year observations on each row__
    - what does each row represent _actually_ represent? __country__
    - what _should_ each row represent? __country-year__
1. Does each value  have its own cell." __Yes__

### `table4b`
```{r}
table4b
```
Answers pretty much the same as `table4a`, except `table4b` shows data for `population` rather than `cases'

### `table5`
```{r}
table5
```
1. Does each variable have its own column? __No__
    - if not, how does the dataset violate this principle? __Two problems. First, the single variable `year' is spread across two columns `century` and `year`. Second, the `rate` column contains the two variables `cases` and `population`__
    - what _should_ the variables be? __country, year, cases, population__
1. Does each observation have its own row? __Yes__
    - what does each row represent _actually_ represent? __country, year__
    - what _should_ each row represent?  __country, year__
1. Does each value  have its own cell?" __No__
    - if not, how does the dataset violate this principle? __Two problems. First, the each value of `year' is spread across two cells. Second, the each cell of the `rate` column contains two values, one for `cases` and one for `population`__

## Revisiting definitions of variables and observations

NEED TO CLEAN THIS SECTION UP; CUT AND REFINE
Worthwhile to revisit Wickham's (2014) defintions of _variables_, and _observations_ in light of what we now know about tidy vs. untidy data.

Whenever I work with datasets I tend to think of observations as being synonomous with rows and variables as being synonomous with columns. But if we use Wickham's definitions of observations and variables, this is not true.

- Wickham definition of __variables__: "A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units"
    - In a tidy dataset, variables and columns are the same thing. 
    - In an untidy dataset, variables and columns are not the same thing; A single variable (i.e., attribute) may be represented by two columns (e.g., in `table2` the attribute `population` required two columns, `type` and `count`)
- Wickham definition of __observations__: "An observation contains all values measured on the same unit (like a person, or a day)...across attributes"
    - In a tidy dataset, an observations is the same thing as a row
    - In an untidy dataset, the values for a particular unit may be spread across multiple rows. 
    For example, in `table1` and `table2` Wickham would think of `country-year` as the proper __unit__. `table1` has one row per `country-year` but `table2` has two rows per `country-year`. 
- __unit__. Wickham tends to think of unit as what each observation represents (e.g., a person, a person-year)
    - By contrast (right or wrong): I tend to think of unit as what each row of data _actually_ represents (e.g., country-year-type)

So what can we take away from this?

- Can think of Wickham's definitions of variables and observations as belonging only to tidy datasets.
- Can think of Wickham's definitions of variables and observations as what _should be_. 
- In real world, we encounter many untidy datasets. We can still equate variables with columns and rows with observations. 
    - Just be mindful that you are using the "everyday" definitions of variables and observations rather than the Wickham definitions.

OTHER STUFF TO SAY [?TO REPLACE ABOVE?]

- In everyday usage, the terms _variable_ and _observation_ refer to data structure, with :
    - variables=columns
    - observations=rows
- In Wickham's definition, the terms _variables_ and _observation_ refer to data contents, with:
    - A variable containing all values of one attribute for all _units_
    - An observation contains the value of all attributes for one _unit_ 
- Based on Wickham's definition, variables=columns and observations=rows __only__ if the dataset is tidy


## Why tidy data 

Why should you create tidy datasets before conducting analyses?

1. If you have a consistent organizational structure for analysis datasets, easier to learn tools that for analyzing data

2. tidy datasets are optimal for R
- Base R functions and tidyverse functions are designed to work with vectors of values
- In a tidy dataset, each column is the vector of values for a given variable, as shown below

```{r}
str(table1)
str(table1$country)
str(table1$cases)
```
Example: how woudl you calculate `rate` variable (`=cases/population*10000`) for `table1` and `table2`

```{r}
#table1
table1 %>% 
  mutate(rate = cases / population * 10000)

#just looking at table2, obvious that calculating rate is much harder
#table2
```

### But tidy data is not always best

Datasets are often stored in an untidy structure rather than a tidy structure when the untidy structure has a smaller file size than the tidy structure

- smaller file-size leads to faster processing time, which is very important for web applications (e.g., facebook) and data visualizations (e.g., interactive maps)

## Legacy concepts: "Long" vs. "wide" data

Prior to Wickham (2014) and the creation of the "tidyverse," the concepts of "tidy"/"untidy" (adjective) data and "tidying" (verb) did not exist.  Instead, researchers would "reshape" (verb) data from "long" (adjective) to "wide" (adjective) and vice-versa

Think "wide" and "long" as alternative presentations of the exact same data
__"wide" data__ Data represented with fewer rows and more columns
__"long" data__ Data represented with more rows and fewer columns

Example, Table 204.10 of the Digest for Education Statistics shows changer over time in the number and percentage of K-12 students on free/reduced lunch [LINK](http://nces.ed.gov/programs/digest/d14/tables/dt14_204.10.asp)

- Wide form display of data:
```{r}
#load("data/nces_digest/nces_digest_table_204_10.RData")
load("../../data/nces_digest/nces_digest_table_204_10.RData")
table204_10
```
- Long form display of data: 
```{r}
total<-table204_10%>%select(state,tot_2000,tot_2010,tot_2011,tot_2012)
names(total)<-c("state","2000","2010","2011","2012")
total_long<-total%>%gather(`2000`,`2010`,`2011`,`2012`,key=year,value=total_students)
total_long<- total_long %>% arrange(state,year)
head(total_long, n=10)
```

Note that the concepts "wide" vs. "long" are relative rather than absolute

- For example, comparing `table4a` and `table1`: `table4a` is wide and `table1` is long
```{r}
table4a
table1
```
- But comparing `table1` and `table2`: `table1` is wide and `table2` is long
```{r}
table1
table2
```



```{r}
table4a
table1
table2

```

# Tidying data:

Steps in tidying untidy data:

1. Diagnose the problem
    - Which principles of tidy data are violated and how are they violated?
    - What _should_ the unit of analysis be? What _should_ the variables and observations be?
2. Sketch out what the tidy data should look like    
3. Transform untidy to tidy

## Common causes of untidy data

Tidy data can only have one organizational structure. 

However, untidy data can have several different organizational structures. In turn, several _causes_ of untidy data exist. Important to identify the most common causes of untidy data, so that we can develop solutions for each common cause.

__The two most common and most important causes of untidy data__

1. Some of the column names are not names of variables, but values of a variable" (e.g, `table4a`, `table4b`), which results in:
    - a single variable spread (e.g., `population`) over multiple columns (e.g., `1999`, `2000`)
    - a single row contains multiple observations
```{r}
table4b
```
    
2. An observation is scattered across multiple rows (e.g., `table2`), such that:
    - One column identifies variable type (e.g., `type`) and another column contains the values for each variable (e.g., `count`)
```{r}
table2
```
__Other common causes of untidy data (less important and/or less common)__

3. Individual cells in a column contain data from two variables (e.g., the `rate` column in `table3`)
```{r}
table3
```
4. Values from a single variable separated into two columns (e.g., in `table5`, values of the 4-digit `year`variable are separated into the two columns, `century` and 2-digit `year` )
```{r}
table5
```


## Tidying data: gathering

As discussed above, the first common reason for untidy data is, some of the column names are not names of variables, but values of a variable (e.g., `table4a`, `table4b`)
```{r}
table4a
```

The solution to this problem is to transform the untidy columns (which represent variable values) into rows

- In the tidyverse, this process is called "gathering"
- Outside the tidyverse, this process is called "reshaping" from "wide" to "long"

In the above example, we want to transform `table4a` into something tha tlooks like this:
```{r}
table1 %>% select(country, year, cases)
```

We gather using the `gather()` function from the`tidyr` package. 
```{r}
#?gather
```

Gathering requires knowing three parameters:

1. names of the set of columns that represent values, not variables in your untidy data 
    - These are existing columns of the untidy data
    - in table 4a these are the columns `1999` and `2000`
2. __key variable__ : variable name you will assign to columns you are gathering from the untidy data
    - This var doesn't yet exist in untidy data, but will be a variable name in the tidy data
    - For the `table4a` example, we'll call this variable `year` because the values of this variable will be years
    - Said different: the "key" is the variable you will create whose values will be the column names from the untidy data. 
3. __value variable__: The name of the variable that will contain values in the tidy dataset you create and whose values are spread across multiple columns in the untidy dataset
    - This var doesn't yet exist in untidy data, but will be a variable name in the tidy data
    - in the `table4a` example, we'll call the "value variable" `cases` because the values refer to number of cases
    
```{r}
table4a %>% gather(`1999`, `2000`, key = "year", value = "cases")
#Note that we write `1999` rather than 1999 because the column name starts with a number

#This would work not work
#table4a %>% gather(1999, 2000, key = "year", value = "cases")

#But giving different names to the key variable and the value variable is fine
table4a %>% gather(`1999`, `2000`, key = "yr", value = "num_cases")
```
### Real-world example of gathering [STUDENT TASK OR OZAN LEADS?]

The following dataset is drawn from Table 204.10 of the NCES Digest for Education Statistics. It shows  change over time in the number and percentage of K-12 students on free/reduced lunch for selected years. [LINK](http://nces.ed.gov/programs/digest/d14/tables/dt14_204.10.asp)
```{r}
load("../../data/nces_digest/nces_digest_table_204_10.RData")
total<-table204_10%>%select(state,tot_2000,tot_2010,tot_2011,tot_2012)
head(total)
```

__Task (using the data frame `total`)__: 

1. Diagnose the problem with the data frame `total`
2. Sketch out what the tidy data should look like    
3. Transform untidy to tidy

__Solution to task__

1. Diagnose the problem with the data frame `total`
    - Column names `tot_2000`, `tot_2010`, etc. are not variables; rather they refer to values of the variable `year`
    - Currently each observation represents a state with separate enrollment variables for each year. 
    - Each observation _should_ be a state-year, with only one variable for enrollment
2. Sketch out what the tidy data should look like    
3. Transform untidy to tidy
```{r}
total_tidy <- total %>% 
  gather(tot_2000,tot_2010,tot_2011,tot_2012,key=year,value=total_students)

total_tidy<- total_tidy %>% arrange(state,year)

head(total_tidy, n=10)
```

Note: often helpful to rename columns of untidy data -- removing characters -- prior to gathering
```{r}
totalv2 <- table204_10%>%select(state,tot_2000,tot_2010,tot_2011,tot_2012)
names(totalv2)<-c("state","2000","2010","2011","2012")
head(totalv2)

total_tidyv2 <- totalv2 %>% 
  gather(`2000`,`2010`,`2011`,`2012`,key=year,value=total_students)

total_tidyv2<- total_tidyv2 %>% arrange(state,year)

head(total_tidyv2, n=10)
```
Complete the task above, keeping the free-reduced enrollment variables in addition to the total enrollment variables [ASK PATRICIA TO FIGURE OUT THE EASIEST WAY TO DO THIS THAT DOESN'T REQUIRE ADVANCED PROGRAMMING]
```{r, eval=FALSE}
totfrl <- table204_10%>%select(state,tot_2000,tot_2010,tot_2011,tot_2012,frl_2000,frl_2010,frl_2011,frl_2012)

#names(totalv2)<-c("state","2000","2010","2011","2012")
#head(totalv2)

totfrl_tidy <- totfrl %>% 
  gather(tot_2000,tot_2010,tot_2011,tot_2012,key=year,value=total_students)

total_tidyv2<- total_tidyv2 %>% arrange(state,year)

head(total_tidyv2, n=10)
```
## Tidying data: spreading

The second important and common cause of untidy data is when an observation is scattered across multiple rows with one column identifies variable type and another column contains the values for each variable.

`table2` is an example of this sort of problem
```{r}
table2
```

This sort of data structure is __very__ common "in the wild"; often data you download have this structure and it is up to you to tidy before analyses

The solution to this problem is to transform the untidy rows (which represent different variables) into columns

- In the tidyverse, this process is called "spreading" (we spread observations across multiple columns); spreading is the opposite of gathering
- Outside the tidyverse, this process is called "reshaping" from "long" to "wide"

Goal: we want to transform `table2` so it looks like `table1`
```{r, eval=FALSE}
table2
table1
```

We spread observations into columns using the `spread()` function from the`tidyr` package. 
```{r, eval=FALSE}
?spread
```

Spreading requires knowing two parameters, which are the parameters of `spread()`:

1. __key column__. Column name in the untidy data whose values will become variable names in the tidy data
that contains variable names
    - this variable name exists in the untidy data
    - in `table2` the key column is `type`; the values of `type`, `cases` and `population`, will become variable names in the tidy data 

1. __value column__. Column name in untidy data that contains values for the new variables that will be created in the tidy data
    - this is a varname that exists in the untidy data
    - in `table2` the value column is `count`; the values of `count` will become the values of the new variables `cases` and `population` in the tidy data

```{r}
table2
table2 %>%
    spread(key = type, value = count)
```

### Real-world example of spreading

IPEDS data on 12-month enrollment headcount for 2015-16 academic year
```{r}
library(haven)
library(labelled)
ipeds_hc_all <- read_dta(file="../../data/ipeds/effy/ey15-16_hc.dta", encoding=NULL)

ipeds_hc <- ipeds_hc_all %>% select(instnm,unitid,lstudy,efytotlt,efytotlm,efytotlw)
head(ipeds_hc)

ipeds_hc %>% select(lstudy) %>% val_labels()
```
__Task__: 

1. Diagnose the problem with the data frame
2. Sketch out what the tidy data should look like    
3. Transform untidy to tidy

__Solution__:

1. Diagnose the problem with the data frame

Investigate the data
```{r}
#what does each observation represent
ipeds_hc %>% group_by(unitid,lstudy) %>% # group_by our candidate
  mutate(n_per_id=n()) %>% # calculate number of obs per group
  ungroup() %>% # ungroup the data
  count(n_per_id==1) # count "true that only one obs per group"

ipeds_hc <- ipeds_hc %>% arrange(unitid, lstudy)
head(ipeds_hc, n=20)
```

    - separate rows for each value of level of study and only one enrollment variable for each type of student (e.g., men, women, men+women)
    - In untidy data, each observation represents college-level_of_study
    - Each observation _should_ represent a college, with separate variabels for each level of study
2. Sketch out what the tidy data should look like    
3. Transform untidy to tidy

```{r}
ipeds_hc %>% select(instnm,unitid,lstudy,efytotlt) %>%
    spread(key = lstudy, value = efytotlt)

#helpful to create a character version of variable lstudy
ipeds_hc %>% select(lstudy) %>% val_labels()
str(ipeds_hc$lstudy)

ipeds_hcv2 <- ipeds_hc %>% 
  mutate(level=recode(as.integer(lstudy),
    `1` = "ug",
    `3` = "grad",
    `999` = "all")
  ) %>% select(-lstudy)

head(ipeds_hcv2)

ipeds_hcv2 %>% select(instnm,unitid,level,efytotlt) %>%
    spread(key = level, value = efytotlt)

```

1. __key column__. Column name in the untidy data whose values will become variable names in the tidy data
that contains variable names
    - this variable name exists in the untidy data
    - in `table2` the key column is `type`; the values of `type`, `cases` and `population`, will become variable names in the tidy data 

1. __value column__. Column name in untidy data that contains values for the new variables that will be created in the tidy data
    - this is a varname that exists in the untidy data
    - in `table2` the value column is `count`; the values of `count` will become the values of the new variables `cases` and `population` in the tidy data

Complete the task above, but having multiple value column (e.g., male enrollment, white male enrollment, etc)[ASK PATRICIA TO FIGURE OUT THE EASIEST WAY TO DO THIS THAT DOESN'T REQUIRE ADVANCED PROGRAMMING]

# Missing values

## Explicit and implicit missing values

This section deals with missing variables and tidying data.

But first, it is helpful to create a new version of the IPEDS enrollment dataset as follows:

- keeps observations for for-profit colleges
- keeps the following enrollment variables: 
    - total enrollment
    - enrollment of students who identify as "Black or African American"
```{r}
ipeds_hc_na <- ipeds_hc_all %>% filter(sector %in% c(3,6,9)) %>% #keep only for-profit colleges
  select(instnm,unitid,lstudy,efytotlt,efybkaam) %>% 
  mutate(level=recode(as.integer(lstudy), # create recoded version of lstudy
    `1` = "ug",
    `3` = "grad",
    `999` = "all")
  ) %>% select(instnm,unitid,level,efytotlt,efybkaam) %>% 
  arrange(unitid,desc(level))
```
Now, let's print some rows

- There is one row for each college-level_of_study
- Some colleges have three rows of data (ug, grad, all)
- Colleges that don't have any undergraduates or don't have any graduate students only have two rows of data
```{r}
ipeds_hc_na
```
Now let's create new versions of the enrollment variables, that replace `0` with `NA`
```{r}
ipeds_hc_na <- ipeds_hc_na %>% 
  mutate(
    efytotltv2 = ifelse(efytotlt == 0, NA, efytotlt),
    efybkaamv2 = ifelse(efybkaam == 0, NA, efybkaam)
  ) %>% select(instnm,unitid,level,efytotlt,efytotltv2,efybkaam,efybkaamv2)

ipeds_hc_na %>% select(unitid,level,efytotlt,efytotltv2,efybkaam,efybkaamv2)
```
Create dataset that drops the original enrollment variables, keeps enrollment vars that replace `0` with `NA`
```{r}
ipeds_hc_nav2 <- ipeds_hc_na %>% select(-efytotlt,-efybkaam)
```
Now we can introduce the concepts of _explicit_ and _implicit_ missing values

There are two types of missing values:

- __Explicit missing values__: variable has the value `NA` for a parcitular row
- __Implicit missing values__: the row is simply not present in the data

Let's print data for the first two colleges
```{r}
ipeds_hc_nav2 %>% head(, n=5)
```
`South University-Montgomery` has three rows:

- variable `efytotltv2` has `0` explicit missing values and `0` implicit missing values
- variable `efybkaamv2` has `0` explicit missing values and `0` implicit missing values

`South University-Montgomery` has two rows (because they have no graduate students):

- variable `efytotltv2` has `0` explicit missing values and `1` implicit missing values (no row for grad students)
- variable `efybkaamv2` has `2` explicit missing values and `1` implicit missing values (no row for grad students)

Let's look at another dataset called `stocks`, which shows stock `return` for each year and quarter for some hypothetical company. 

- Wickham uses this dataset introduce explicit and implicit missing values

```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
stocks # note: this data is already tidy
```
The variable `return` has:

- `1` _explicit_ missing value in `year==2015` and `qtr==4`
- `1` _implicit_ missing value in `year==2016` and `qtr==4`; this row of data simply does not exist


```{r}
stocks %>% 
  complete(year, qtr)
```
## Making implicit missing values explicit

An _Implicit_ missing value is the result of a row not existing. If you want to make an an implicit missing value explicit, then make the non-existant row exist.

The `complete()` function within the `tidyr` package turns implicit missing values into explicit missing values

- Basically, you specificy the object (i.e., data frame) and a list of variables; 
- `complete()` returns an object that has all unique combinations of those variables, including those not found in the original data frame
- I'll skip additinoal options and complications

```{r}
stocks
stocks %>% complete(year, qtr)
```
Note that we now have a row for `year==2016` and `qtr==1` that has an _explicit_ missing value for `return`

Let's apply `complete()` to our IPEDS dataset

```{r}
ipeds_hc_nav2

ipeds_complete <- ipeds_hc_nav2 %>% select(unitid,level,efytotltv2,efybkaamv2) %>%
  complete(unitid, level)

ipeds_complete

#Confirm that the "complete" dataset always has three observations per unitid
ipeds_complete %>% group_by(unitid) %>% summarise(n=n()) %>% count(n)

#Note that previous dataset did not
ipeds_hc_nav2 %>% group_by(unitid) %>% summarise(n=n()) %>% count(n)
```
Should you make _implicit_ missing values _explicit_?

- No clear-cut answer; depends on many context-specific things about your project
- The important thing is to be aware of the presence of implicit missing values (both in the "input" datasets you read-in and the datasets you create from this inputs) and be purposeful about how you deal with implicit missing values
    - This is the sort of thing sloppy researchers forget/ignore
- My recommendation for the stage of creating analysis datasets from input data:
    - If you feel unsure about making implicit values explicit, then I recommend making them explicit
    - This forces you to be more fully aware of patterns of missing data; helps you avoid careless mistakes down the road
    - After making implicit missing values explicit, you can drop these rows once you are sure you don't need them

## Spreading and explicit/implicit missing values

We use `spread()` to transform rows into columns; outside the tidyverse, referred to as reshaping from "long" to "wide"

Let's look at two datasets that have similar structure. Which one of these is in need of tidying?
```{r}
stocks

ipeds_hc_nav2 %>% select (instnm,unitid,level,efytotltv2) %>% head(n=5)
```
Let's use `spread()` to tidy the IPEDS dataset, focusing on the total enrollment variable which has implicit missing values but no explicit missing values
```{r}
ipeds_hc_nav2 %>% select (instnm,unitid,level,efytotltv2) %>%
  spread(key = level, value = efytotltv2) %>% 
  arrange(unitid) %>% head(n=5)
```
The resulting dataset has explicint missing values (i.e,. `NAs`) for rows that had implicit missing values in the input data.

Let's use `spread()` the IPEDS dataset again, this time focusing on the Black enrollment variable which has both explicit and implicit missing values
```{r}
ipeds_hc_nav2 %>% select (instnm,unitid,level,efybkaamv2) %>% head(n=5)

ipeds_hc_nav2 %>% select (instnm,unitid,level,efybkaamv2) %>%
  spread(key = level, value = efybkaamv2) %>% 
  arrange(unitid) %>% head(n=5)
```

The resulting dataset has explicit missing values (i.e,. `NAs`) for rows that had implicit missing values in the input data and for rows that has explicit missing values in the data.

What if we spread a dataset that has explicit missing values and no implicit missing values?

- Resulting dataset has explicit missing values (i.e,. `NAs`) for rows that weere explicit missing values in the input data.
    
```{r}
ipeds_complete %>% select(unitid,level,efybkaamv2) %>%
  spread(key = level, value = efybkaamv2) %>% 
  arrange(unitid) %>% head(n=5)
```
__Takeways about `spread()` and missing values__

- Explicit missing values in the input data become explicit missing values in the resulting dataset
- Implicit missing values in the input data become explicit missing values in the resulting dataset

Therefore, no need to make implicit missing values explicit (using `complete()`) prior to spreading

## Gathering and explicit/implicit missing values

We use `gather()` to transform columns into rows; outside the tidyverse, referred to as reshaping from "wide" to "long"

Let's create a dataset in need of gathering

- start w/ IPEDS dataset that has enrollment for Black students
- create a fictitious 2017 enrollment variable equal to 2016 enrollment + 20
- rename the enrollment vars `2016` and `2017`

```{r}
ipeds_gather <- ipeds_hc_nav2 %>% select (instnm,unitid,level,efybkaamv2) 


ipeds_gather <- ipeds_hc_nav2 %>% select (instnm,unitid,level,efybkaamv2) %>%
  mutate(
    efybkaamv2_2017= ifelse(!is.na(efybkaamv2),efybkaamv2+20,20)
  ) %>%
  rename("2016"=efybkaamv2,"2017"=efybkaamv2_2017)

ipeds_gather %>% head(n=10)

```
- The variable `2016` has both implicit and explicit missing values
- The variable `2017` has implicit but no explicit missing values

Let's use `gather()` to transform the columns `2016` and `2017` into rows
```{r}
ipeds_gatherv2 <- ipeds_gather %>% 
  gather(`2016`,`2017`,key=year,value=efybkaam) %>%
  arrange(unitid,desc(level),year) %>%
  arrange(unitid,desc(level),year) 

ipeds_gatherv2 %>% head(n=10)
```

Before looking at missing values, let's investigate data structure
```{r}
#number of rows after gathering is exactly 2X number of rows in input dataset
nrow(ipeds_gather)
nrow(ipeds_gatherv2)
nrow(ipeds_gatherv2)==nrow(ipeds_gather)*2

#How many observations for each combination of unitid and level? 
  #always 2: one for 2016 and one for 2017
ipeds_gatherv2 %>% group_by(unitid,level) %>% 
  summarise(n_per_unitid_level=n()) %>% ungroup %>% count(n_per_unitid_level)

#How many observations for each unitid? 
  # 4 observations for colleges that had two rows in the input dataset
  # 6 observations for colleges that had three rows in the input dataset
ipeds_gatherv2 %>% group_by(unitid) %>% 
  summarise(n_per_unitid=n()) %>% ungroup %>% count(n_per_unitid)

```

Let's compare the data before and after gathering for one college
```{r}
#before gathering
ipeds_gather %>% filter(unitid==101277)
#after gathering
ipeds_gatherv2 %>% filter(unitid==101277)
```
__Takeaways about gathering and explicit/implicit missing values__

- Explicit missing values from the input dataset become explicit missing values in the resulting dataset after gathering
- Implicit missing values from the input dataset are implicit missing values the resulting dataset after gathering. Why:
    - In the input dataset, no row existed for these implicit missing values
    - For each existing row in the input dataset, `gather()` creates new rows
    - `gather()` does nothing to rows that do not exist in the input dataset

Therefore, if you want to make implicit values explicit after gathering, then prior to gathering you should use `complete()` to make missing values explicit

# Tidying data: separating and uniting [SKIP]

```{r}
table5
```
- "Separating" is for dealing with the problem in the `rate` column
- "Uniting" is for dealing with the problem in the `century` and `year` columns

Read about this in section 12.4 of Wickham text, but no homework questions on separating and uniting
